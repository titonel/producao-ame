import streamlit as st
import pandas as pd
from sqlalchemy import create_engine, text
import openpyxl
import plotly.express as px
from io import BytesIO
import os 
import json # Importar para carregar dados geojson

# Importa as fun√ß√µes de processamento de upload do arquivo uploads.py
from uploads import normalizar_especialidade, process_siresp_upload, process_contratos_upload, process_cdr_upload

# --- Gest√£o de Usu√°rios (para demonstra√ß√£o, usar m√©todo seguro em produ√ß√£o) ---
USERS = {
    "ame_user": "ame_password",  # Substitua por uma forma segura de armazenar/recuperar credenciais
    "admin": "admin_password"
}

def authenticate(username, password):
    """
    Fun√ß√£o para autenticar o usu√°rio.
    Em uma aplica√ß√£o real, verificar com senhas hash.
    """
    if username in USERS and USERS[username] == password:
        return True
    return False

# Fun√ß√£o para carregar o GeoJSON com cache
@st.cache_data
def load_geojson(path):
    """
    Carrega um arquivo GeoJSON do caminho especificado e o armazena em cache.
    Retorna os dados GeoJSON ou None em caso de erro.
    """
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        st.error(f"‚ùå Erro: O arquivo '{path}' n√£o foi encontrado. Por favor, certifique-se de que ele est√° no mesmo diret√≥rio do seu aplicativo.")
        return None
    except json.JSONDecodeError:
        st.error(f"‚ùå Erro: O arquivo '{path}' n√£o √© um JSON v√°lido ou est√° corrompido.")
        return None
    except Exception as e:
        st.error(f"‚ùå Erro inesperado ao carregar o GeoJSON: {e}")
        return None

# Lista de meses para ordena√ß√£o correta
meses_ordem = ['janeiro', 'fevereiro', 'mar√ßo', 'abril', 'maio', 'junho',
               'julho', 'agosto', 'setembro', 'outubro', 'novembro', 'dezembro']

# --- Configura√ß√£o da p√°gina ---
st.set_page_config(page_title="Produ√ß√£o M√©dica AME", layout="wide")

# --- L√≥gica da P√°gina de Login ---
# Inicializa o estado de autentica√ß√£o se ainda n√£o estiver definido
if 'authenticated' not in st.session_state:
    st.session_state.authenticated = False
if 'username' not in st.session_state:
    st.session_state.username = None

# Se o usu√°rio n√£o estiver autenticado, exibe a p√°gina de login
if not st.session_state.authenticated:
    st.title("Login - AME Caraguatatuba")
    st.markdown("---") # Separador visual

    username = st.text_input("Usu√°rio", key="login_username")
    password = st.text_input("Senha", type="password", key="login_password")

    if st.button("Entrar", key="login_button"):
        if authenticate(username, password):
            st.session_state.authenticated = True
            st.session_state.username = username  # Armazena o nome de usu√°rio no estado da sess√£o
            st.success(f"Bem-vindo, {username}!")
            st.rerun()  # Recarrega a p√°gina para mostrar a aplica√ß√£o principal
        else:
            st.error("Usu√°rio ou senha inv√°lidos.")
    st.markdown("---") # Separador visual
    st.info("Use 'ame_user' como usu√°rio e 'ame_password' como senha para testar.")
    st.info("Ou 'admin' como usu√°rio e 'admin_password' como senha.")

# Se o usu√°rio estiver autenticado, exibe a aplica√ß√£o principal
else:
    st.title("üìä AME Caraguatatuba")
    st.title("üìä Sistema de Produ√ß√£o M√©dica")

    # Navega√ß√£o lateral
    pagina = st.sidebar.radio("Escolha a op√ß√£o:", ["Performance", "Dados Gerais", "Uploads", "Absente√≠smo", "Custos M√©dicos", "CDR"])
    
    # Bot√£o de Sair na barra lateral
    st.sidebar.markdown("---")
    if st.sidebar.button("Sair", key="logout_button"):
        st.session_state.authenticated = False
        st.session_state.username = None
        st.rerun() # Recarrega a p√°gina para voltar √† tela de login

    # Conex√£o com o banco SQLite
    engine = create_engine('sqlite:///producao.db')

    # P√°gina: UPLOADS
    if pagina == "Uploads":
        st.header("‚¨ÜÔ∏è Upload de Arquivos")
        
        st.subheader("Upload de Dados de Produ√ß√£o (SIRESP)")
        uploaded_file_producao = st.file_uploader("Selecione o arquivo de produ√ß√£o (Excel: .xlsx, .xls; CSV: .csv)", type=["xlsx", "xls", "csv"], key="upload_producao")

        if uploaded_file_producao:
            # Chama a fun√ß√£o do uploads.py para processar o arquivo
            process_siresp_upload(uploaded_file_producao, engine)
        
        st.markdown("---") # Separador para os uploads

        st.subheader("Upload de Dados de Custos M√©dicos (Contratos)")
        uploaded_file_contratos = st.file_uploader("Selecione o arquivo Excel de contratos", type=["xlsx"], key="upload_contratos")

        if uploaded_file_contratos:
            # Chama a fun√ß√£o do uploads.py para processar o arquivo
            process_contratos_upload(uploaded_file_contratos, engine)
        
        st.markdown("---") # Separador para os uploads

        st.subheader("Upload de Dados de CDR (CSV)")
        uploaded_file_cdr = st.file_uploader("Selecione o arquivo CSV de CDR", type=["csv"], key="upload_cdr")

        if uploaded_file_cdr:
            # Chama a fun√ß√£o do uploads.py para processar o arquivo CDR
            process_cdr_upload(uploaded_file_cdr, engine)

    # P√°gina: INSERIR DADOS (Agora vazia, pois o upload foi movido para 'Uploads')
    elif pagina == "Inserir Dados":
        st.header("‚ÑπÔ∏è Informa√ß√µes sobre Inser√ß√£o de Dados")
        st.info("A funcionalidade de upload de dados foi movida para a p√°gina 'Uploads'.")


    # P√°gina: PERFORMANCE
    elif pagina == "Performance":
        st.header("üìà Performance das Agendas M√©dicas por Especialidade")
        
        try:
            df = pd.read_sql_table('producao', con=engine)

            # Remover c√≥digos num√©ricos iniciais da especialidade
            df['Especialidade'] = df['Especialidade'].astype(str).str.replace(r'^\d+\s*', '', regex=True).str.strip()

            # Normalizar nomes com agrupamento gen√©rico
            df['Especialidade_Normalizada'] = df['Especialidade'].apply(normalizar_especialidade)
            df['Mes_Producao'] = df['Mes_Producao'].astype(str).str.lower() # Garante min√∫sculas para compara√ß√£o
            df['Mes_Num'] = df['Mes_Producao'].apply(lambda x: meses_ordem.index(x) + 1 if x in meses_ordem else 0)

            # Filtros para a p√°gina de Performance
            anos = sorted(df['Ano_Producao'].unique())
            meses = sorted(df['Mes_Producao'].unique(), key=lambda x: meses_ordem.index(x.lower()))
            especialidades = sorted(df['Especialidade_Normalizada'].unique())

            st.sidebar.subheader("üîé Filtros de Performance")
            ano_filtro = st.sidebar.multiselect("Ano", anos, default=anos, key="perf_ano")
            mes_filtro = st.sidebar.multiselect("M√™s", meses, default=meses, key="perf_mes")
            especialidade_filtro = st.sidebar.multiselect("Especialidade", especialidades, default=especialidades, key="perf_especialidade")

            # Aplicar filtros
            df_filtro = df[
                (df['Ano_Producao'].isin(ano_filtro)) &
                (df['Mes_Producao'].isin(mes_filtro)) &
                (df['Especialidade_Normalizada'].isin(especialidade_filtro))
            ]

            if df_filtro.empty:
                st.warning("Nenhum dado encontrado para os filtros selecionados.")
            else:
                # Agrupar por especialidade normalizada e somar Oferta, Agendados e Realizados
                df_agrupado = df_filtro.groupby('Especialidade_Normalizada').agg({
                    'Oferta': 'sum',
                    'Agendados': 'sum',
                    'Realizados': 'sum'
                }).reset_index()

                # Criar o gr√°fico de barras
                fig = px.bar(
                    df_agrupado,
                    x='Especialidade_Normalizada',
                    y='Realizados',
                    title='Total de Atendimentos Realizados por Especialidade',
                    labels={'Especialidade_Normalizada': 'Especialidade', 'Realizados': 'Atendimentos Realizados'},
                    color='Realizados' # Opcional: colore as barras com base no valor de Realizados
                )
                fig.update_xaxes(tickangle=45) # Inclina os r√≥tulos do eixo X para melhor legibilidade
                fig.update_yaxes(rangemode="tozero") # Come√ßa o eixo Y em zero

                st.plotly_chart(fig, use_container_width=True)

                st.subheader("Dados Detalhados de Performance")
                st.dataframe(df_agrupado.rename(columns={'Especialidade_Normalizada': 'Especialidade'}), use_container_width=True)

        except Exception as e:
            st.error(f"Erro ao carregar dados de performance: {e}")

    elif pagina == "Dados Gerais":
        st.header("üìã Dados Gerais Consolidados")

        try:
            df = pd.read_sql_table('producao', con=engine)
            
            # Remover c√≥digos num√©ricos iniciais da especialidade
            df['Especialidade'] = df['Especialidade'].astype(str).str.replace(r'^\d+\s*', '', regex=True).str.strip()

            # Normalizar nomes com agrupamento gen√©rico
            df['Especialidade_Normalizada'] = df['Especialidade'].apply(normalizar_especialidade)
            df['Mes_Producao'] = df['Mes_Producao'].astype(str).str.lower() # Garante min√∫sculas para compara√ß√£o

            # Filtros
            anos = sorted(df['Ano_Producao'].unique())
            meses = sorted(df['Mes_Producao'].unique(), key=lambda x: meses_ordem.index(x.lower()))

            st.sidebar.subheader("üîé Filtros Gerais")
            ano_filtro = st.sidebar.multiselect("Ano", anos, default=anos, key="geral_ano")
            mes_filtro = st.sidebar.multiselect("M√™s", meses, default=meses, key="geral_mes")

            # Aplicar filtros
            df_filtro = df[
                (df['Ano_Producao'].isin(ano_filtro)) &
                (df['Mes_Producao'].isin(mes_filtro))
            ]

            if df_filtro.empty:
                st.warning("Nenhum dado dispon√≠vel para os filtros selecionados.")
            else:
                # Agrupar dados por Especialidade consolidada
                df_grouped = (
                    df_filtro
                    .groupby(['Especialidade_Normalizada', 'Ano_Producao', 'Mes_Producao'])
                    .agg({
                        'Oferta': 'sum',
                        'Agendados': 'sum',
                        'Realizados': 'sum'
                    })
                    .reset_index()
                    .rename(columns={
                        'Especialidade_Normalizada': 'Especialidade',
                        'Ano_Producao': 'Ano',
                        'Mes_Producao': 'M√™s'
                    })
                )

                # Calcular Absente√≠smo com tratamento de divis√£o por zero
                df_grouped['Absente√≠smo'] = df_grouped.apply(
                    lambda row: 1 - (row['Realizados'] / row['Agendados']) if row['Agendados'] and row['Agendados'] > 0 else 0,
                    axis=1
                )

                df_grouped['Absente√≠smo (%)'] = (df_grouped['Absente√≠smo'] * 100).round(2).astype(str).str.replace('.', ',', regex=False) + '%'
                
                st.dataframe(df_grouped, use_container_width=True)
                
                # Exportar como Excel
                output = BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    df_grouped.to_excel(writer, index=False, sheet_name='Dados')
                processed_data = output.getvalue()

                st.download_button(
                    label="üì• Baixar como Excel",
                    data=processed_data,
                    file_name="dados_consolidados.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

        except Exception as e:
            st.error(f"‚ùå Erro ao carregar os dados: {e}")

    # P√°gina: ABSENTE√çSMO
    elif pagina == "Absente√≠smo":
        st.header("üìâ Taxa de Absente√≠smo por Especialidade")

        try:
            df = pd.read_sql_table('producao', con=engine)

            # Remover c√≥digos num√©ricos iniciais da especialidade
            df['Especialidade'] = df['Especialidade'].astype(str).str.replace(r'^\d+\s*', '', regex=True).str.strip()

            # Normalizar nomes com agrupamento gen√©rico
            df['Especialidade_Normalizada'] = df['Especialidade'].apply(normalizar_especialidade)
            df['Mes_Producao'] = df['Mes_Producao'].astype(str).str.lower()
            df['Mes_Num'] = df['Mes_Producao'].apply(lambda x: meses_ordem.index(x) + 1 if x in meses_ordem else 0)

            # Filtros para a p√°gina de Absente√≠smo
            anos = sorted(df['Ano_Producao'].unique())
            meses = sorted(df['Mes_Producao'].unique(), key=lambda x: meses_ordem.index(x.lower()))
            especialidades = sorted(df['Especialidade_Normalizada'].unique())

            st.sidebar.subheader("üîé Filtros de Absente√≠smo")
            ano_filtro_abs = st.sidebar.multiselect("Ano", anos, default=anos, key="abs_ano")
            mes_filtro_abs = st.sidebar.multiselect("M√™s", meses, default=meses, key="abs_mes")
            especialidade_filtro_abs = st.sidebar.multiselect("Especialidade", especialidades, default=especialidades, key="abs_especialidade")

            # Aplicar filtros
            df_filtro = df[
                (df['Ano_Producao'].isin(ano_filtro_abs)) &
                (df['Mes_Producao'].isin(mes_filtro_abs)) &
                (df['Especialidade_Normalizada'].isin(especialidade_filtro_abs))
            ]

            if df_filtro.empty:
                st.warning("Nenhum dado encontrado para os filtros selecionados.")
            else:
                # Agrupar por per√≠odo e especialidade normalizada
                df_grouped_abs = (
                    df_filtro
                    .groupby(['Ano_Producao', 'Mes_Producao', 'Mes_Num', 'Especialidade_Normalizada'])
                    .agg({
                        'Agendados': 'sum',
                        'Realizados': 'sum'
                    })
                    .reset_index()
                )

                # Calcular Absente√≠smo
                df_grouped_abs['Absente√≠smo'] = df_grouped_abs.apply(
                    lambda row: (1 - (row['Realizados'] / row['Agendados'])) * 100
                    if row['Agendados'] and row['Agendados'] > 0 else 0,
                    axis=1
                )
                df_grouped_abs['Absente√≠smo'] = df_grouped_abs['Absente√≠smo'].round(2)

                # Criar coluna de per√≠odo para o eixo X e ordenar
                df_grouped_abs['Periodo'] = df_grouped_abs['Mes_Num'].astype(str).str.zfill(2) + '/' + df_grouped_abs['Ano_Producao'].astype(str)
                df_grouped_abs = df_grouped_abs.sort_values(by=['Ano_Producao', 'Mes_Num'])

                # Criar o gr√°fico de linha
                fig_abs = px.line(
                    df_grouped_abs,
                    x='Periodo',
                    y='Absente√≠smo',
                    color='Especialidade_Normalizada',
                    title='Taxa de Absente√≠smo por Especialidade',
                    markers=True,
                    labels={'Absente√≠smo': 'Absente√≠smo (%)', 'Periodo': 'Per√≠odo (M√™s/Ano)', 'Especialidade_Normalizada': 'Especialidade'},
                    hover_data={'Absente√≠smo': ':.2f%', 'Periodo': True, 'Especialidade_Normalizada': True} # Formata tooltip
                )

                fig_abs.update_layout(
                    hovermode="x unified" # Melhora a intera√ß√£o do hover
                )
                fig_abs.update_yaxes(rangemode="tozero") # Come√ßa o eixo Y em zero
                fig_abs.update_xaxes(tickangle=45) # Inclina os r√≥tulos do eixo X para melhor legibilidade

                st.plotly_chart(fig_abs, use_container_width=True)

                st.subheader("Dados Detalhados de Absente√≠smo")
                # Prepara os dados para exibi√ß√£o em tabela Streamlit (com formata√ß√£o de v√≠rgula)
                df_display_for_st = df_grouped_abs.copy()
                df_display_for_st['Absente√≠smo (%)'] = df_display_for_st['Absente√≠smo'].astype(str).str.replace('.', ',', regex=False) + '%'
                st.dataframe(df_display_for_st[['Ano_Producao', 'Mes_Producao', 'Especialidade_Normalizada', 'Agendados', 'Realizados', 'Absente√≠smo (%)']], use_container_width=True)
                
                # Exportar como Excel
                output = BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    # Seleciona as colunas desejadas para exporta√ß√£o, usando o valor num√©rico de 'Absente√≠smo'
                    df_to_export = df_grouped_abs[['Ano_Producao', 'Mes_Producao', 'Especialidade_Normalizada', 'Agendados', 'Realizados', 'Absente√≠smo']].copy()
                    
                    # Garante que 'Ano_Producao' seja do tipo inteiro
                    df_to_export['Ano_Producao'] = df_to_export['Ano_Producao'].astype(int)

                    df_to_export.to_excel(writer, index=False, sheet_name='Dados')

                    # Acessa o workbook e o worksheet para aplicar a formata√ß√£o num√©rica
                    workbook = writer.book
                    worksheet = writer.sheets['Dados']

                    # Cria um formato de porcentagem (Excel usar√° a localidade para ponto/v√≠rgula)
                    percent_format = workbook.add_format({'num_format': '0.00%', 'align': 'center'})
                    
                    # Encontra o √≠ndice da coluna 'Absente√≠smo' no DataFrame que ser√° exportado
                    absenteismo_col_idx = df_to_export.columns.get_loc('Absente√≠smo')
                    
                    # Aplica o formato √† coluna de Absente√≠smo no Excel
                    worksheet.set_column(absenteismo_col_idx, absenteismo_col_idx, None, percent_format)

                processed_data = output.getvalue()

                st.download_button(
                    label="üì• Baixar como Excel",
                    data=processed_data,
                    file_name="dados_consolidados_absenteismo.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )


        except Exception as e:
            st.error(f"‚ùå Erro ao carregar dados de absente√≠smo: {e}")

    # P√°gina: Custos M√©dicos (agora para visualiza√ß√£o, n√£o upload)
    elif pagina == "Custos M√©dicos":
        st.header("üí∏ Visualiza√ß√£o e An√°lise de Custos M√©dicos - Contratos")
        
        try:
            # Tenta ler os dados da tabela de contratos
            df_contratos = pd.read_sql_table('contratos', con=engine)
            
            if df_contratos.empty:
                st.warning("Nenhum dado de contrato encontrado. Por favor, fa√ßa o upload dos dados na p√°gina 'Uploads'.")
            else:
                st.subheader("Dados dos Contratos Ativos")
                
                # Exibir um dataframe com os dados dos contratos
                st.dataframe(df_contratos, use_container_width=True)

                # Voc√™ pode adicionar filtros e gr√°ficos para analisar os custos aqui
                st.subheader("An√°lise de Custos (Em Desenvolvimento)")
                st.info("Funcionalidades adicionais para an√°lise de custos ser√£o implementadas aqui.")

        except Exception as e:
            st.error(f"‚ùå Erro ao carregar os dados de contratos: {e}")
            st.info("Verifique se a tabela 'contratos' existe no banco de dados. Se n√£o existir, fa√ßa o upload de um arquivo de contratos na p√°gina 'Uploads'.")
    
    # Nova P√°gina: CDR
    elif pagina == "CDR":
        st.header("üó∫Ô∏è Mapa de Dados de CDR por Munic√≠pio")

        try:
            df_cdr = pd.read_sql_table('cdr', con=engine)

            if df_cdr.empty:
                st.warning("Nenhum dado de CDR encontrado. Por favor, fa√ßa o upload dos dados na p√°gina 'Uploads'.")
            else:
                # Carregar dados GeoJSON para o mapa usando a fun√ß√£o cacheada
                geojson_data = load_geojson("geojs-35-mun.json")

                if geojson_data:
                    # Assumindo que 'Valor' no df_cdr representa a quantidade de pacientes ou uma m√©trica similar
                    # Se 'Valor' n√£o for a quantidade de pacientes, voc√™ precisar√° agrupar e contar aqui.
                    # Exemplo: df_cdr_grouped = df_cdr.groupby('Munic√≠pio').size().reset_index(name='Quantidade_Pacientes')
                    # E ent√£o usar 'Quantidade_Pacientes' no `color` do px.choropleth

                    # Obter lista de munic√≠pios para o filtro
                    municipios_disponiveis = sorted(df_cdr['Munic√≠pio'].unique())
                    
                    st.sidebar.subheader("üîé Filtro de Munic√≠pio (CDR)")
                    # Adicionar um seletor para filtrar por munic√≠pio
                    selected_municipio = st.sidebar.selectbox(
                        "Selecione um Munic√≠pio para filtrar a tabela:",
                        ['Todos'] + municipios_disponiveis,
                        key="cdr_municipio_filter"
                    )

                    df_cdr_filtered = df_cdr.copy()
                    if selected_municipio != 'Todos':
                        df_cdr_filtered = df_cdr_filtered[df_cdr_filtered['Munic√≠pio'] == selected_municipio]
                        st.subheader(f"Dados de CDR para: {selected_municipio}")
                    else:
                        st.subheader("Dados de CDR por Munic√≠pio")

                    st.dataframe(df_cdr_filtered, use_container_width=True)

                    # Criar o mapa coropl√©tico
                    fig_map = px.choropleth(
                        df_cdr, # Usar o DataFrame completo para o mapa, para mostrar todos os munic√≠pios
                        geojson=geojson_data,
                        locations='Munic√≠pio', # Coluna no df_cdr que cont√©m os nomes dos munic√≠pios
                        featureidkey="properties.name", # Propriedade no GeoJSON que corresponde aos nomes dos munic√≠pios
                        color='Valor', # Coluna no df_cdr para colorir o mapa (assumindo quantidade de pacientes ou m√©trica)
                        color_continuous_scale="Viridis", # Escala de cores
                        scope="south america", # Define o escopo do mapa (pode ser "brazil" se tiver um GeoJSON do Brasil)
                        title="Distribui√ß√£o de Valores por Munic√≠pio (CDR)",
                        hover_name="Munic√≠pio",
                        hover_data={"Valor": True}
                    )
                    
                    fig_map.update_geos(fitbounds="locations", visible=False) # Ajusta o zoom para os munic√≠pios presentes
                    fig_map.update_layout(margin={"r":0,"t":0,"l":0,"b":0}) # Remove margens

                    st.plotly_chart(fig_map, use_container_width=True)
                else:
                    st.warning("N√£o foi poss√≠vel carregar o GeoJSON, o mapa n√£o ser√° exibido.")

        except Exception as e:
            st.error(f"‚ùå Erro ao carregar ou exibir o mapa de CDR: {e}")
            st.info("Certifique-se de que o arquivo CSV de CDR cont√©m a coluna 'Munic√≠pio' e que os nomes dos munic√≠pios correspondem aos dados do GeoJSON.")
            st.info("Para um mapa coropl√©tico funcional, voc√™ precisar√° de um arquivo GeoJSON com as geometrias dos munic√≠pios brasileiros. Um exemplo pode ser encontrado buscando por 'geojson munic√≠pios Brasil'.")

